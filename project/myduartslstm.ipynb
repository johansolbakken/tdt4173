{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bf84246-fdcc-4ea1-9eba-2f09ab028196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from darts import TimeSeries\n",
    "from darts.models import LightGBMModel\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d1cc4e-355b-48f8-971e-477578505948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | rnn             | LSTM             | 11.2 K | train\n",
      "6 | V               | Linear           | 204    | train\n",
      "-------------------------------------------------------------\n",
      "11.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.4 K    Total params\n",
      "0.046     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726639bbcc1746c891ca85291eb0e486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from darts import TimeSeries\n",
    "from darts.models import RNNModel\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "import warnings\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set default tensor dtype to float32\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "# Check if MPS is available and set device accordingly\n",
    "device = 'cpu'\n",
    "if torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "\n",
    "# Load ais_train.csv with separator '|'\n",
    "train_df = pd.read_csv('ais_train.csv', sep='|')\n",
    "train_df['time'] = pd.to_datetime(train_df['time'])\n",
    "\n",
    "# Load ais_test.csv with separator ','\n",
    "test_df = pd.read_csv('ais_test.csv', sep=',')\n",
    "test_df['time'] = pd.to_datetime(test_df['time'])\n",
    "\n",
    "# Use 'vesselId' instead of 'vessel_id'\n",
    "# Select only vessel IDs that are in both train and test datasets\n",
    "common_vessel_ids = set(train_df['vesselId']).intersection(set(test_df['vesselId']))\n",
    "train_df = train_df[train_df['vesselId'].isin(common_vessel_ids)]\n",
    "\n",
    "# Additional features to include\n",
    "feature_columns = ['latitude', 'longitude', 'cog', 'sog']  # Add other relevant features if available\n",
    "\n",
    "# Preprocess the data\n",
    "timeseries_dict = {}\n",
    "last_train_time = {}\n",
    "scaler_dict = {}\n",
    "\n",
    "# Process each vesselId group\n",
    "for vessel_id, group_df in train_df.groupby('vesselId'):\n",
    "    # Sort on time\n",
    "    group_df = group_df.sort_values('time')\n",
    "    # Set index to time\n",
    "    group_df = group_df.set_index('time')\n",
    "    # Select features\n",
    "    features_df = group_df[feature_columns]\n",
    "    # Resample data to 30-minute frequency with mean and interpolate\n",
    "    features_df = features_df.resample('30T').mean().interpolate(method='linear')\n",
    "    # Ensure data is in float32\n",
    "    features_df = features_df.astype(np.float32)\n",
    "    # Create TimeSeries object without 'dtype' parameter\n",
    "    ts = TimeSeries.from_dataframe(features_df)\n",
    "    # Convert TimeSeries data to float32 using astype()\n",
    "    ts = ts.astype(np.float32)\n",
    "    # Scaling the data\n",
    "    scaler = Scaler()\n",
    "    ts_scaled = scaler.fit_transform(ts)\n",
    "    # Store the TimeSeries object and last training time\n",
    "    timeseries_dict[vessel_id] = ts_scaled\n",
    "    last_train_time[vessel_id] = features_df.index.max()\n",
    "    scaler_dict[vessel_id] = scaler\n",
    "\n",
    "# Initialize a dictionary to store predictions\n",
    "predictions = {}\n",
    "\n",
    "# Fit RNN models and predict for each TimeSeries object\n",
    "for vessel_id, ts_scaled in timeseries_dict.items():\n",
    "    # Get the last training time\n",
    "    last_time = last_train_time[vessel_id]\n",
    "    # Get test times for this vessel\n",
    "    vessel_test_df = test_df[test_df['vesselId'] == vessel_id]\n",
    "    test_times = vessel_test_df['time']\n",
    "    if test_times.empty:\n",
    "        continue  # Skip if no test times for this vessel\n",
    "    # Compute the time differences in 30-minute intervals\n",
    "    time_diffs = (test_times - last_time).dt.total_seconds() / (30 * 60)\n",
    "    # Get the maximum forecast horizon needed\n",
    "    max_n = int(np.ceil(time_diffs.max()))\n",
    "    if max_n <= 0:\n",
    "        continue  # Skip if no future times to predict\n",
    "    # Initialize RNN model with hyperparameter tuning\n",
    "    model = RNNModel(\n",
    "        model='LSTM',\n",
    "        hidden_dim=50,\n",
    "        dropout=0.2,\n",
    "        batch_size=16,\n",
    "        n_epochs=200,\n",
    "        optimizer_kwargs={'lr': 1e-3},\n",
    "        model_name=f'RNNModel_{vessel_id}',\n",
    "        log_tensorboard=False,  # Set to False if not using TensorBoard\n",
    "        random_state=42,\n",
    "        input_chunk_length=24,\n",
    "        output_chunk_length=12,\n",
    "        likelihood=None,\n",
    "        # Ensure the model uses the correct device\n",
    "        pl_trainer_kwargs={\n",
    "            \"accelerator\": device,\n",
    "            \"devices\": 1\n",
    "        }\n",
    "    )\n",
    "    # Fit the model\n",
    "    model.fit(ts_scaled)\n",
    "    # Predict up to the maximum horizon needed\n",
    "    forecast_scaled = model.predict(n=max_n)\n",
    "    # Inverse transform the forecast\n",
    "    forecast = scaler_dict[vessel_id].inverse_transform(forecast_scaled)\n",
    "    # Store the forecast and last time\n",
    "    predictions[vessel_id] = (forecast, last_time)\n",
    "\n",
    "# Initialize a list to store submission rows\n",
    "submission_rows = []\n",
    "\n",
    "# Generate predictions for the submission file\n",
    "for idx, row in test_df.iterrows():\n",
    "    vessel_id = row['vesselId']\n",
    "    test_time = row['time']\n",
    "    test_id = row['ID']  # Assuming 'ID' column exists in test_df\n",
    "    # Check if predictions are available for this vessel_id\n",
    "    if vessel_id in predictions:\n",
    "        forecast_ts, last_time = predictions[vessel_id]\n",
    "        time_diff = (test_time - last_time).total_seconds() / (30 * 60)\n",
    "        index = int(np.round(time_diff)) - 1  # Adjust index\n",
    "        # Check if index is within forecast horizon\n",
    "        if 0 <= index < len(forecast_ts):\n",
    "            predicted_lat = forecast_ts['latitude'].values()[index][0]\n",
    "            predicted_lon = forecast_ts['longitude'].values()[index][0]\n",
    "        else:\n",
    "            predicted_lat = np.nan\n",
    "            predicted_lon = np.nan\n",
    "    else:\n",
    "        predicted_lat = np.nan\n",
    "        predicted_lon = np.nan\n",
    "    # Append the prediction to the submission list\n",
    "    submission_rows.append({\n",
    "        'ID': test_id,\n",
    "        'longitude_predicted': predicted_lon,\n",
    "        'latitude_predicted': predicted_lat\n",
    "    })\n",
    "\n",
    "# Create a submission DataFrame from the list\n",
    "submission_df = pd.DataFrame(submission_rows)\n",
    "\n",
    "# Save the submission file\n",
    "submission_df.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dd99c9-5e3b-4cdb-8441-08622523e92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize a list to store submission rows\n",
    "submission_rows = []\n",
    "\n",
    "# Generate predictions for the submission file\n",
    "for idx, row in test_df.iterrows():\n",
    "    vessel_id = row['vesselId']\n",
    "    test_time = row['time']\n",
    "    test_id = row['ID']  # Assuming 'ID' column exists in test_df\n",
    "    # Check if predictions are available for this vessel_id\n",
    "    if vessel_id in predictions:\n",
    "        forecast_ts, last_time = predictions[vessel_id]\n",
    "        time_diff = (test_time - last_time).total_seconds() / (30 * 60)\n",
    "        index = int(np.round(time_diff)) - 1  # Adjust index\n",
    "        # Check if index is within forecast horizon\n",
    "        if 0 <= index < len(forecast_ts):\n",
    "            predicted_lat = forecast_ts['latitude'].values()[index][0]\n",
    "            predicted_lon = forecast_ts['longitude'].values()[index][0]\n",
    "        else:\n",
    "            predicted_lat = np.nan\n",
    "            predicted_lon = np.nan\n",
    "    else:\n",
    "        predicted_lat = np.nan\n",
    "        predicted_lon = np.nan\n",
    "    # Append the prediction to the submission list\n",
    "    submission_rows.append({\n",
    "        'ID': test_id,\n",
    "        'longitude_predicted': predicted_lon,\n",
    "        'latitude_predicted': predicted_lat\n",
    "    })\n",
    "\n",
    "# Create a submission DataFrame from the list\n",
    "submission_df = pd.DataFrame(submission_rows)\n",
    "\n",
    "# Save the submission file\n",
    "submission_df.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
