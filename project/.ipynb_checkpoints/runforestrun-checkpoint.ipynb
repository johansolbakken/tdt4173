{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a814ba7c-92f7-4f4c-99f9-c6f9a6b8d2f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'lonitude'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/py310/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'lonitude'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m X_train \u001b[38;5;241m=\u001b[39m train[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvesselId\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprevious_lat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprevious_lon\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelta_time\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     35\u001b[0m y_train_lat \u001b[38;5;241m=\u001b[39m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 36\u001b[0m y_train_lon \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlonitude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Initialize 'previous_lat', 'previous_lon', and 'delta_time' in the test set\u001b[39;00m\n\u001b[1;32m     39\u001b[0m test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprevious_lat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n",
      "File \u001b[0;32m~/miniforge3/envs/py310/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniforge3/envs/py310/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'lonitude'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Load training data\n",
    "train = pd.read_csv('ais_train.csv', sep='|')\n",
    "\n",
    "# Load test data\n",
    "test = pd.read_csv('ais_test.csv', sep=',')\n",
    "\n",
    "# Convert 'time' column to datetime\n",
    "train['time'] = pd.to_datetime(train['time'])\n",
    "test['time'] = pd.to_datetime(test['time'])\n",
    "\n",
    "# Map 'vesselId' to unique integers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train['vesselId'] = le.fit_transform(train['vesselId'])\n",
    "test['vesselId'] = le.transform(test['vesselId'])\n",
    "\n",
    "# Sort datasets by 'vesselId' and 'time'\n",
    "train = train.sort_values(by=['vesselId', 'time'])\n",
    "test = test.sort_values(by=['vesselId', 'time'])\n",
    "\n",
    "# Create 'previous_lat', 'previous_lon', and 'delta_time' in the training set\n",
    "train['previous_lat'] = train.groupby('vesselId')['latitude'].shift(1)\n",
    "train['previous_lon'] = train.groupby('vesselId')['longitude'].shift(1)\n",
    "train['delta_time'] = train.groupby('vesselId')['time'].diff().dt.total_seconds()\n",
    "\n",
    "# Drop rows with missing values resulting from the shift operation\n",
    "train = train.dropna(subset=['previous_lat', 'previous_lon', 'delta_time'])\n",
    "\n",
    "# Prepare training features and targets\n",
    "X_train = train[['vesselId', 'previous_lat', 'previous_lon', 'delta_time']]\n",
    "y_train_lat = train['latitude']\n",
    "y_train_lon = train['longitude']\n",
    "\n",
    "# Initialize 'previous_lat', 'previous_lon', and 'delta_time' in the test set\n",
    "test['previous_lat'] = np.nan\n",
    "test['previous_lon'] = np.nan\n",
    "test['delta_time'] = np.nan\n",
    "\n",
    "# Retrieve last known positions from the training set\n",
    "last_positions = train.groupby('vesselId').apply(lambda x: x.iloc[-1])[['vesselId', 'latitude', 'longitude', 'time']]\n",
    "last_positions = last_positions.set_index('vesselId')\n",
    "\n",
    "# Train separate Random Forest models for latitude and longitude\n",
    "model_lat = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model_lat.fit(X_train, y_train_lat)\n",
    "\n",
    "model_lon = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model_lon.fit(X_train, y_train_lon)\n",
    "\n",
    "# Prepare a list to collect the prediction results\n",
    "submission_rows = []\n",
    "\n",
    "# Loop over each vessel in the test data\n",
    "for vessel_id in test['vesselId'].unique():\n",
    "    vessel_test_data = test[test['vesselId'] == vessel_id].copy()\n",
    "    vessel_test_data = vessel_test_data.sort_values(by='time')\n",
    "    \n",
    "    # Check if the vessel_id exists in the last_positions\n",
    "    if vessel_id in last_positions.index:\n",
    "        prev_lat = last_positions.loc[vessel_id, 'latitude']\n",
    "        prev_lon = last_positions.loc[vessel_id, 'longitude']\n",
    "        last_time = last_positions.loc[vessel_id, 'time']\n",
    "    else:\n",
    "        # If vessel_id is not in the training data, skip prediction\n",
    "        continue\n",
    "    \n",
    "    # Iterate over each record for the vessel\n",
    "    for idx, row in vessel_test_data.iterrows():\n",
    "        delta_time = (row['time'] - last_time).total_seconds()\n",
    "        \n",
    "        # Prepare the feature vector\n",
    "        X_test_row = pd.DataFrame({\n",
    "            'vesselId': [vessel_id],\n",
    "            'previous_lat': [prev_lat],\n",
    "            'previous_lon': [prev_lon],\n",
    "            'delta_time': [delta_time]\n",
    "        })\n",
    "        \n",
    "        # Predict latitude and longitude\n",
    "        predicted_lat = model_lat.predict(X_test_row)[0]\n",
    "        predicted_lon = model_lon.predict(X_test_row)[0]\n",
    "        \n",
    "        # Update previous values for the next iteration\n",
    "        prev_lat = predicted_lat\n",
    "        prev_lon = predicted_lon\n",
    "        last_time = row['time']\n",
    "        \n",
    "        # Append the prediction to the submission list\n",
    "        submission_rows.append({\n",
    "            'ID': row['ID'],\n",
    "            'longitude_predicted': predicted_lon,\n",
    "            'latitude_predicted': predicted_lat\n",
    "        })\n",
    "\n",
    "# Create a submission DataFrame from the list\n",
    "submission_df = pd.DataFrame(submission_rows)\n",
    "\n",
    "# Merge the predictions with the test data based on 'ID'\n",
    "final_submission = test[['ID']].merge(submission_df, on='ID', how='left')\n",
    "\n",
    "# Save the submission file\n",
    "final_submission.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
