{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a814ba7c-92f7-4f4c-99f9-c6f9a6b8d2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5q/k66vnm0d2ps_3_nhtc3cx0qr0000gn/T/ipykernel_35504/2648211968.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  last_positions = train.groupby('vesselId').apply(lambda x: x.iloc[-1])[['vesselId', 'latitude', 'longitude', 'time']]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Load training data\n",
    "train = pd.read_csv('ais_train.csv', sep='|')\n",
    "\n",
    "# Load test data\n",
    "test = pd.read_csv('ais_test.csv', sep=',')\n",
    "\n",
    "# Convert 'time' column to datetime\n",
    "train['time'] = pd.to_datetime(train['time'])\n",
    "test['time'] = pd.to_datetime(test['time'])\n",
    "\n",
    "# Map 'vesselId' to unique integers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train['vesselId'] = le.fit_transform(train['vesselId'])\n",
    "test['vesselId'] = le.transform(test['vesselId'])\n",
    "\n",
    "# Sort datasets by 'vesselId' and 'time'\n",
    "train = train.sort_values(by=['vesselId', 'time'])\n",
    "test = test.sort_values(by=['vesselId', 'time'])\n",
    "\n",
    "# Create 'previous_lat', 'previous_lon', and 'delta_time' in the training set\n",
    "train['previous_lat'] = train.groupby('vesselId')['latitude'].shift(1)\n",
    "train['previous_lon'] = train.groupby('vesselId')['longitude'].shift(1)\n",
    "train['delta_time'] = train.groupby('vesselId')['time'].diff().dt.total_seconds()\n",
    "\n",
    "# Drop rows with missing values resulting from the shift operation\n",
    "train = train.dropna(subset=['previous_lat', 'previous_lon', 'delta_time'])\n",
    "\n",
    "# Prepare training features and targets\n",
    "X_train = train[['vesselId', 'previous_lat', 'previous_lon', 'delta_time']]\n",
    "y_train_lat = train['latitude']\n",
    "y_train_lon = train['longitude']\n",
    "\n",
    "# Initialize 'previous_lat', 'previous_lon', and 'delta_time' in the test set\n",
    "test['previous_lat'] = np.nan\n",
    "test['previous_lon'] = np.nan\n",
    "test['delta_time'] = np.nan\n",
    "\n",
    "# Retrieve last known positions from the training set\n",
    "last_positions = train.groupby('vesselId').apply(lambda x: x.iloc[-1])[['vesselId', 'latitude', 'longitude', 'time']]\n",
    "last_positions = last_positions.set_index('vesselId')\n",
    "\n",
    "# Train separate Random Forest models for latitude and longitude\n",
    "model_lat = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "model_lat.fit(X_train, y_train_lat)\n",
    "\n",
    "model_lon = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "model_lon.fit(X_train, y_train_lon)\n",
    "\n",
    "# Prepare a list to collect the prediction results\n",
    "submission_rows = []\n",
    "\n",
    "# Loop over each vessel in the test data\n",
    "for vessel_id in test['vesselId'].unique():\n",
    "    vessel_test_data = test[test['vesselId'] == vessel_id].copy()\n",
    "    vessel_test_data = vessel_test_data.sort_values(by='time')\n",
    "    \n",
    "    # Check if the vessel_id exists in the last_positions\n",
    "    if vessel_id in last_positions.index:\n",
    "        prev_lat = last_positions.loc[vessel_id, 'latitude']\n",
    "        prev_lon = last_positions.loc[vessel_id, 'longitude']\n",
    "        last_time = last_positions.loc[vessel_id, 'time']\n",
    "    else:\n",
    "        # If vessel_id is not in the training data, skip prediction\n",
    "        continue\n",
    "    \n",
    "    # Iterate over each record for the vessel\n",
    "    for idx, row in vessel_test_data.iterrows():\n",
    "        delta_time = (row['time'] - last_time).total_seconds()\n",
    "        \n",
    "        # Prepare the feature vector\n",
    "        X_test_row = pd.DataFrame({\n",
    "            'vesselId': [vessel_id],\n",
    "            'previous_lat': [prev_lat],\n",
    "            'previous_lon': [prev_lon],\n",
    "            'delta_time': [delta_time]\n",
    "        })\n",
    "        \n",
    "        # Predict latitude and longitude\n",
    "        predicted_lat = model_lat.predict(X_test_row)[0]\n",
    "        predicted_lon = model_lon.predict(X_test_row)[0]\n",
    "        \n",
    "        # Update previous values for the next iteration\n",
    "        prev_lat = predicted_lat\n",
    "        prev_lon = predicted_lon\n",
    "        last_time = row['time']\n",
    "        \n",
    "        # Append the prediction to the submission list\n",
    "        submission_rows.append({\n",
    "            'ID': row['ID'],\n",
    "            'longitude_predicted': predicted_lon,\n",
    "            'latitude_predicted': predicted_lat\n",
    "        })\n",
    "\n",
    "# Create a submission DataFrame from the list\n",
    "submission_df = pd.DataFrame(submission_rows)\n",
    "\n",
    "# Merge the predictions with the test data based on 'ID'\n",
    "final_submission = test[['ID']].merge(submission_df, on='ID', how='left')\n",
    "\n",
    "# Save the submission file\n",
    "final_submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b18454-a4e9-4527-a006-17ef6514ee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597997a6-75d1-4488-be69-24af21e363df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ----------------------------\n",
    "# Step 1: Load and Preprocess Data\n",
    "# ----------------------------\n",
    "\n",
    "# Load training data\n",
    "train = pd.read_csv('ais_train.csv', sep='|')\n",
    "\n",
    "# Load test data\n",
    "test = pd.read_csv('ais_test.csv', sep=',')\n",
    "\n",
    "# Convert 'time' column to datetime\n",
    "train['time'] = pd.to_datetime(train['time'])\n",
    "test['time'] = pd.to_datetime(test['time'])\n",
    "\n",
    "# Map 'vesselId' to unique integers\n",
    "le = LabelEncoder()\n",
    "train['vesselId'] = le.fit_transform(train['vesselId'])\n",
    "test['vesselId'] = le.transform(test['vesselId'])\n",
    "\n",
    "# Sort datasets by 'vesselId' and 'time'\n",
    "train = train.sort_values(by=['vesselId', 'time']).reset_index(drop=True)\n",
    "test = test.sort_values(by=['vesselId', 'time']).reset_index(drop=True)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 2: Create Lag Features\n",
    "# ----------------------------\n",
    "\n",
    "# Create first-lag features\n",
    "train['previous_lat'] = train.groupby('vesselId')['latitude'].shift(1)\n",
    "train['previous_lon'] = train.groupby('vesselId')['longitude'].shift(1)\n",
    "train['delta_time'] = train.groupby('vesselId')['time'].diff().dt.total_seconds()\n",
    "\n",
    "# Create second-lag features\n",
    "train['previous_lat_2'] = train.groupby('vesselId')['latitude'].shift(2)\n",
    "train['previous_lon_2'] = train.groupby('vesselId')['longitude'].shift(2)\n",
    "train['delta_time_2'] = train.groupby('vesselId')['time'].shift(1).diff().dt.total_seconds()\n",
    "\n",
    "# Drop rows with missing values resulting from the shift operations\n",
    "train = train.dropna(subset=[\n",
    "    'previous_lat', 'previous_lon', 'delta_time',\n",
    "    'previous_lat_2', 'previous_lon_2', 'delta_time_2'\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "# Prepare training features and targets\n",
    "X_train = train[[\n",
    "    'vesselId', \n",
    "    'previous_lat', 'previous_lon', 'delta_time',\n",
    "    'previous_lat_2', 'previous_lon_2', 'delta_time_2'\n",
    "]]\n",
    "y_train_lat = train['latitude']\n",
    "y_train_lon = train['longitude']\n",
    "\n",
    "# ----------------------------\n",
    "# Step 3: Train the Models\n",
    "# ----------------------------\n",
    "\n",
    "# Initialize and train the Random Forest models\n",
    "model_lat = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "model_lat.fit(X_train, y_train_lat)\n",
    "\n",
    "model_lon = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "model_lon.fit(X_train, y_train_lon)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 4: Prepare for Prediction\n",
    "# ----------------------------\n",
    "\n",
    "# Initialize second-lag features in the test set\n",
    "test['previous_lat'] = np.nan\n",
    "test['previous_lon'] = np.nan\n",
    "test['delta_time'] = np.nan\n",
    "test['previous_lat_2'] = np.nan\n",
    "test['previous_lon_2'] = np.nan\n",
    "test['delta_time_2'] = np.nan\n",
    "\n",
    "# ----------------------------\n",
    "# Step 5: Prediction Loop\n",
    "# ----------------------------\n",
    "\n",
    "# Prepare a list to collect the prediction results\n",
    "submission_rows = []\n",
    "\n",
    "# Iterate over each unique vessel in the test set\n",
    "for vessel_id in test['vesselId'].unique():\n",
    "    vessel_test_data = test[test['vesselId'] == vessel_id].copy()\n",
    "    vessel_test_data = vessel_test_data.sort_values(by='time')\n",
    "    \n",
    "    # Retrieve all historical data for the vessel from the training set\n",
    "    vessel_train_data = train[train['vesselId'] == vessel_id].sort_values(by='time')\n",
    "    \n",
    "    # Check if there are at least two historical records to create lags\n",
    "    if len(vessel_train_data) < 2:\n",
    "        # If insufficient history, skip predictions for this vessel\n",
    "        print(f\"Skipping vesselId {vessel_id} due to insufficient historical data.\")\n",
    "        continue\n",
    "    \n",
    "    # Get the last two known positions\n",
    "    last_two = vessel_train_data.iloc[-2:]\n",
    "    prev_lat_2 = last_two.iloc[0]['latitude']\n",
    "    prev_lon_2 = last_two.iloc[0]['longitude']\n",
    "    prev_lat = last_two.iloc[1]['latitude']\n",
    "    prev_lon = last_two.iloc[1]['longitude']\n",
    "    last_time = last_two.iloc[1]['delta_time']\n",
    "    \n",
    "    # Iterate over each record for the vessel in the test set\n",
    "    for idx, row in vessel_test_data.iterrows():\n",
    "        # Calculate the time difference from the last known time\n",
    "        delta_time = row['delta_time'] - last_time\n",
    "        \n",
    "        # Prepare the feature vector with second-lag features\n",
    "        X_test_row = pd.DataFrame({\n",
    "            'vesselId': [vessel_id],\n",
    "            'previous_lat': [prev_lat],\n",
    "            'previous_lon': [prev_lon],\n",
    "            'delta_time': [delta_time],\n",
    "            'previous_lat_2': [prev_lat_2],\n",
    "            'previous_lon_2': [prev_lon_2],\n",
    "            'delta_time_2': [last_time]\n",
    "        })\n",
    "        \n",
    "        # Predict latitude and longitude\n",
    "        predicted_lat = model_lat.predict(X_test_row)[0]\n",
    "        predicted_lon = model_lon.predict(X_test_row)[0]\n",
    "        \n",
    "        # Update previous values for the next iteration\n",
    "        prev_lat_2, prev_lon_2 = prev_lat, prev_lon\n",
    "        prev_lat, prev_lon = predicted_lat, predicted_lon\n",
    "        last_time = delta_time\n",
    "        \n",
    "        # Append the prediction to the submission list\n",
    "        submission_rows.append({\n",
    "            'ID': row['ID'],\n",
    "            'longitude_predicted': predicted_lon,\n",
    "            'latitude_predicted': predicted_lat\n",
    "        })\n",
    "\n",
    "# ----------------------------\n",
    "# Step 6: Create and Save Submission\n",
    "# ----------------------------\n",
    "\n",
    "# Create a submission DataFrame from the list\n",
    "submission_df = pd.DataFrame(submission_rows)\n",
    "\n",
    "# Merge the predictions with the test data based on 'ID'\n",
    "final_submission = test[['ID']].merge(submission_df, on='ID', how='left')\n",
    "\n",
    "# Save the submission file\n",
    "final_submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file 'submission.csv' has been successfully created with second-lag features.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
