{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb44530-aef4-4294-8a01-d464c3689877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load training data\n",
    "train = pd.read_csv('ais_train.csv', sep='|')\n",
    "\n",
    "# Load test data\n",
    "test = pd.read_csv('ais_test.csv', sep=',')\n",
    "\n",
    "# Convert 'time' column to datetime\n",
    "train['time'] = pd.to_datetime(train['time'])\n",
    "test['time'] = pd.to_datetime(test['time'])\n",
    "\n",
    "# Map 'vesselId' to unique integers\n",
    "le = LabelEncoder()\n",
    "train['vesselId'] = le.fit_transform(train['vesselId'])\n",
    "test['vesselId'] = le.transform(test['vesselId'])\n",
    "\n",
    "# Sort datasets by 'vesselId' and 'time'\n",
    "train = train.sort_values(by=['vesselId', 'time'])\n",
    "test = test.sort_values(by=['vesselId', 'time'])\n",
    "\n",
    "# Create 'previous_lat', 'previous_lon', and 'delta_time' in the training set\n",
    "train['previous_lat'] = train.groupby('vesselId')['latitude'].shift(1)\n",
    "train['previous_lon'] = train.groupby('vesselId')['longitude'].shift(1)\n",
    "train['delta_time'] = train.groupby('vesselId')['time'].diff().dt.total_seconds()\n",
    "\n",
    "# Drop rows with missing values resulting from the shift operation\n",
    "train = train.dropna(subset=['previous_lat', 'previous_lon', 'delta_time'])\n",
    "\n",
    "# Prepare training features and targets\n",
    "X_train = train[['vesselId', 'previous_lat', 'previous_lon', 'delta_time']]\n",
    "y_train_lat = train['latitude']\n",
    "y_train_lon = train['longitude']\n",
    "\n",
    "# Initialize and fit the scaler on training features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Initialize SVM models for latitude and longitude\n",
    "model_lat = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)\n",
    "model_lon = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)\n",
    "\n",
    "# Fit the SVM models on the scaled training data\n",
    "model_lat.fit(X_train_scaled, y_train_lat)\n",
    "model_lon.fit(X_train_scaled, y_train_lon)\n",
    "\n",
    "# Prepare a list to collect the prediction results\n",
    "submission_rows = []\n",
    "\n",
    "# Retrieve last known positions from the training set\n",
    "last_positions = train.groupby('vesselId').apply(lambda x: x.iloc[-1])[['vesselId', 'latitude', 'longitude', 'time']]\n",
    "last_positions = last_positions.set_index('vesselId')\n",
    "\n",
    "# Loop over each vessel in the test data\n",
    "for vessel_id in test['vesselId'].unique():\n",
    "    vessel_test_data = test[test['vesselId'] == vessel_id].copy()\n",
    "    vessel_test_data = vessel_test_data.sort_values(by='time')\n",
    "    \n",
    "    # Check if the vessel_id exists in the last_positions\n",
    "    if vessel_id in last_positions.index:\n",
    "        prev_lat = last_positions.loc[vessel_id, 'latitude']\n",
    "        prev_lon = last_positions.loc[vessel_id, 'longitude']\n",
    "        last_time = last_positions.loc[vessel_id, 'time']\n",
    "    else:\n",
    "        # If vessel_id is not in the training data, skip prediction\n",
    "        continue\n",
    "    \n",
    "    # Iterate over each record for the vessel\n",
    "    for idx, row in vessel_test_data.iterrows():\n",
    "        delta_time = (row['time'] - last_time).total_seconds()\n",
    "        \n",
    "        # Prepare the feature vector\n",
    "        X_test_row = pd.DataFrame({\n",
    "            'vesselId': [vessel_id],\n",
    "            'previous_lat': [prev_lat],\n",
    "            'previous_lon': [prev_lon],\n",
    "            'delta_time': [delta_time]\n",
    "        })\n",
    "        \n",
    "        # Scale the test feature vector using the same scaler as training data\n",
    "        X_test_scaled = scaler.transform(X_test_row)\n",
    "        \n",
    "        # Predict latitude and longitude using the SVM models\n",
    "        predicted_lat = model_lat.predict(X_test_scaled)[0]\n",
    "        predicted_lon = model_lon.predict(X_test_scaled)[0]\n",
    "        \n",
    "        # Update previous values for the next iteration\n",
    "        prev_lat = predicted_lat\n",
    "        prev_lon = predicted_lon\n",
    "        last_time = row['time']\n",
    "        \n",
    "        # Append the prediction to the submission list\n",
    "        submission_rows.append({\n",
    "            'ID': row['ID'],\n",
    "            'longitude_predicted': predicted_lon,\n",
    "            'latitude_predicted': predicted_lat\n",
    "        })\n",
    "\n",
    "# Create a submission DataFrame from the list\n",
    "submission_df = pd.DataFrame(submission_rows)\n",
    "\n",
    "# Merge the predictions with the test data based on 'ID'\n",
    "final_submission = test[['ID']].merge(submission_df, on='ID', how='left')\n",
    "\n",
    "# Save the submission file\n",
    "final_submission.to_csv('submission1.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
