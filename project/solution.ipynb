{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1f4cc88-33a7-419c-9522-3b2642ed2623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "from geopy.distance import geodesic\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0469301-afbc-4b65-a69e-280eb1ff714d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIS Train Columns: Index(['time', 'cog', 'sog', 'rot', 'heading', 'navstat', 'etaRaw', 'latitude',\n",
      "       'longitude', 'vesselId', 'portId'],\n",
      "      dtype='object')\n",
      "AIS Test Columns: Index(['ID', 'vesselId', 'time', 'scaling_factor'], dtype='object')\n",
      "Vessels Columns: Index(['shippingLineId', 'vesselId', 'CEU', 'DWT', 'GT', 'NT', 'vesselType',\n",
      "       'breadth', 'depth', 'draft', 'enginePower', 'freshWater', 'fuel',\n",
      "       'homePort', 'length', 'maxHeight', 'maxSpeed', 'maxWidth',\n",
      "       'rampCapacity', 'yearBuilt'],\n",
      "      dtype='object')\n",
      "Ports Columns: Index(['portId', 'name', 'portLocation', 'longitude', 'latitude', 'UN_LOCODE',\n",
      "       'countryName', 'ISO'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5q/k66vnm0d2ps_3_nhtc3cx0qr0000gn/T/ipykernel_45986/353493426.py:73: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_data['vesselType'].fillna('Unknown', inplace=True)\n",
      "/var/folders/5q/k66vnm0d2ps_3_nhtc3cx0qr0000gn/T/ipykernel_45986/353493426.py:73: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Unknown' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  merged_data['vesselType'].fillna('Unknown', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_5 (LSTM)               (None, 64)                17408     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,538\n",
      "Trainable params: 17,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "38035/38035 [==============================] - 60s 2ms/step - loss: 31.4146 - val_loss: 24.0009\n",
      "9509/9509 [==============================] - 5s 509us/step\n",
      "Mean Geodetic Error on Validation Set: 3754.141946186506 km\n",
      "   1/1617 [..............................] - ETA: 3:14"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5q/k66vnm0d2ps_3_nhtc3cx0qr0000gn/T/ipykernel_45986/353493426.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_test['vesselType'].fillna('Unknown', inplace=True)\n",
      "/var/folders/5q/k66vnm0d2ps_3_nhtc3cx0qr0000gn/T/ipykernel_45986/353493426.py:31: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Unknown' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  merged_test['vesselType'].fillna('Unknown', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1617/1617 [==============================] - 1s 523us/step\n",
      "Submission file 'submission.csv' has been created.\n"
     ]
    }
   ],
   "source": [
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    return geodesic((lat1, lon1), (lat2, lon2)).kilometers\n",
    "\n",
    "def prepare_sequences(data, feature_cols, target_cols, sequence_length):\n",
    "    X, y = [], []\n",
    "    data_values = data[feature_cols + target_cols].values\n",
    "    for i in range(len(data_values) - sequence_length):\n",
    "        X.append(data_values[i:i+sequence_length, :len(feature_cols)])\n",
    "        y.append(data_values[i+sequence_length-1, len(feature_cols):])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def prepare_test_sequences(data, feature_cols, sequence_length):\n",
    "    X = []\n",
    "    data_values = data[feature_cols].values\n",
    "    for i in range(len(data_values) - sequence_length + 1):\n",
    "        X.append(data_values[i:i+sequence_length])\n",
    "    return np.array(X)\n",
    "\n",
    "def prepare_test_data(ais_test, vessels, vessel_type_categories):\n",
    "    merged_test = ais_test.copy()\n",
    "\n",
    "    # Merge AIS test data with vessel data\n",
    "    merged_test = pd.merge(\n",
    "        merged_test,\n",
    "        vessels[['vesselId', 'vesselType']],\n",
    "        on='vesselId',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Handle missing vesselType\n",
    "    merged_test['vesselType'].fillna('Unknown', inplace=True)\n",
    "\n",
    "    # Extract time-related features\n",
    "    merged_test['time'] = pd.to_datetime(merged_test['time'])\n",
    "    merged_test['hour'] = merged_test['time'].dt.hour\n",
    "    merged_test['day_of_week'] = merged_test['time'].dt.dayofweek\n",
    "\n",
    "    # Encode vessel type as numeric categories (ensure consistency with training data)\n",
    "    merged_test['vesselType'] = pd.Categorical(merged_test['vesselType'], categories=vessel_type_categories)\n",
    "    merged_test['vessel_type_encoded'] = merged_test['vesselType'].cat.codes\n",
    "\n",
    "    # Define the feature columns\n",
    "    features = ['hour', 'day_of_week', 'vessel_type_encoded']\n",
    "\n",
    "    # Handle missing feature values\n",
    "    merged_test[features] = merged_test[features].fillna(0)  # Or appropriate imputation\n",
    "\n",
    "    return merged_test, features\n",
    "\n",
    "def main() -> None:\n",
    "    # Load AIS and optional datasets\n",
    "    ais_train = pd.read_csv('ais_train.csv', sep='|')\n",
    "    ais_test = pd.read_csv('ais_test.csv')  # Removed sep parameter\n",
    "    vessels = pd.read_csv('vessels.csv', sep='|')\n",
    "    ports = pd.read_csv('ports.csv', sep='|')\n",
    "    schedules = pd.read_csv('schedules_to_may_2024.csv', sep='|')\n",
    "\n",
    "    # Verify column names\n",
    "    print(\"AIS Train Columns:\", ais_train.columns)\n",
    "    print(\"AIS Test Columns:\", ais_test.columns)\n",
    "    print(\"Vessels Columns:\", vessels.columns)\n",
    "    print(\"Ports Columns:\", ports.columns)\n",
    "\n",
    "    # Merge AIS data with vessel data to get vessel types and other info\n",
    "    merged_data = pd.merge(\n",
    "        ais_train,\n",
    "        vessels[['vesselId', 'vesselType']],\n",
    "        on='vesselId',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Handle missing vesselType\n",
    "    merged_data['vesselType'].fillna('Unknown', inplace=True)\n",
    "\n",
    "    # Extract time-related features\n",
    "    merged_data['time'] = pd.to_datetime(merged_data['time'])\n",
    "    merged_data['hour'] = merged_data['time'].dt.hour\n",
    "    merged_data['day_of_week'] = merged_data['time'].dt.dayofweek\n",
    "\n",
    "    # Create future latitude and longitude columns by shifting the original values\n",
    "    merged_data = merged_data.sort_values(by=['vesselId', 'time'])\n",
    "    merged_data['future_latitude'] = merged_data.groupby('vesselId')['latitude'].shift(-1)\n",
    "    merged_data['future_longitude'] = merged_data.groupby('vesselId')['longitude'].shift(-1)\n",
    "\n",
    "    # Drop rows with missing future positions\n",
    "    merged_data.dropna(subset=['future_latitude', 'future_longitude'], inplace=True)\n",
    "\n",
    "    # Encode vessel type as numeric categories\n",
    "    merged_data['vesselType'] = merged_data['vesselType'].astype('category')\n",
    "    vessel_type_categories = merged_data['vesselType'].cat.categories\n",
    "    merged_data['vessel_type_encoded'] = merged_data['vesselType'].cat.codes\n",
    "\n",
    "    # Define the feature columns\n",
    "    features = ['hour', 'day_of_week', 'vessel_type_encoded']\n",
    "\n",
    "    # Define the target columns\n",
    "    target = ['future_latitude', 'future_longitude']\n",
    "\n",
    "    # Handle missing feature values\n",
    "    merged_data[features] = merged_data[features].fillna(0)\n",
    "\n",
    "    # Use early data as training, later data as validation\n",
    "    train_data, val_data = train_test_split(merged_data, test_size=0.2, shuffle=False)\n",
    "\n",
    "    sequence_length = 5\n",
    "    X_train, y_train = prepare_sequences(train_data, features, target, sequence_length)\n",
    "    X_val, y_val = prepare_sequences(val_data, features, target, sequence_length)\n",
    "\n",
    "    # Build the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, return_sequences=False, input_shape=(sequence_length, len(features))))\n",
    "    model.add(Dense(2))  # Predict latitude and longitude\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "    model.summary()\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=1, validation_data=(X_val, y_val))\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    predictions_val = model.predict(X_val)\n",
    "    val_data = val_data.iloc[sequence_length:]  # Align with predictions\n",
    "    val_data['pred_latitude'] = predictions_val[:, 0]\n",
    "    val_data['pred_longitude'] = predictions_val[:, 1]\n",
    "\n",
    "    val_data['error_distance'] = val_data.apply(lambda row: calculate_distance(\n",
    "        row['future_latitude'], row['future_longitude'], row['pred_latitude'], row['pred_longitude']), axis=1)\n",
    "\n",
    "    mean_error_distance = val_data['error_distance'].mean()\n",
    "    print(f'Mean Geodetic Error on Validation Set: {mean_error_distance} km')\n",
    "\n",
    "    # Prepare test data\n",
    "    merged_test, features = prepare_test_data(ais_test, vessels, vessel_type_categories)\n",
    "\n",
    "    # Prepare test sequences\n",
    "    X_test = prepare_test_sequences(merged_test, features, sequence_length)\n",
    "\n",
    "    # Make predictions on test set\n",
    "    predictions_test = model.predict(X_test)\n",
    "\n",
    "    # Align predictions with test data\n",
    "    prediction_indices = np.arange(sequence_length - 1, len(merged_test))\n",
    "    submission_df = merged_test.iloc[prediction_indices].copy()\n",
    "    submission_df['longitude_predicted'] = predictions_test[:, 1]\n",
    "    submission_df['latitude_predicted'] = predictions_test[:, 0]\n",
    "\n",
    "    # Prepare submission file\n",
    "    if 'ID' not in ais_test.columns:\n",
    "        ais_test.reset_index(inplace=True)\n",
    "        ais_test.rename(columns={'index': 'ID'}, inplace=True)\n",
    "\n",
    "    submission_df['ID'] = ais_test.iloc[prediction_indices]['ID'].values\n",
    "    submission_df['ID'] = submission_df['ID'].astype(int)\n",
    "\n",
    "    submission_df = submission_df[['ID', 'longitude_predicted', 'latitude_predicted']]\n",
    "\n",
    "    # Save submission file\n",
    "    submission_df.to_csv('submission.csv', index=False)\n",
    "    print(\"Submission file 'submission.csv' has been created.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
