{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0469301-afbc-4b65-a69e-280eb1ff714d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAisTrain\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Optional\n",
    "from datetime import datetime\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "class AisTrain:\n",
    "    def __init__(self, time: datetime, cog: float, sog: float, rot: int, heading: int, navstat: int, etaRaw: str, latitude: float, longitude: float, vesselId: str, portId: str):\n",
    "        self.time = time\n",
    "        self.cog = cog\n",
    "        self.sog = sog\n",
    "        self.rot = rot\n",
    "        self.heading = heading\n",
    "        self.navstat = navstat\n",
    "        self.etaRaw = etaRaw\n",
    "        self.latitude = latitude\n",
    "        self.longitude = longitude\n",
    "        self.vesselId = vesselId\n",
    "        self.portId = portId\n",
    "\n",
    "class Vessel:\n",
    "    def __init__(self, shippingLineId: str, vesselId: str, CEU: int, DWT: float, GT: float, NT: Optional[float], vesselType: float, homePort: str, length: float, maxHeight: Optional[float], maxSpeed: Optional[float], maxWidth: Optional[float], rampCapacity: Optional[float], yearBuilt: int):\n",
    "        self.shippingLineId = shippingLineId\n",
    "        self.vesselId = vesselId\n",
    "        self.CEU = CEU\n",
    "        self.DWT = DWT\n",
    "        self.GT = GT\n",
    "        self.NT = NT\n",
    "        self.vesselType = vesselType\n",
    "        self.homePort = homePort\n",
    "        self.length = length\n",
    "        self.maxHeight = maxHeight\n",
    "        self.maxSpeed = maxSpeed\n",
    "        self.maxWidth = maxWidth\n",
    "        self.rampCapacity = rampCapacity\n",
    "        self.yearBuilt = yearBuilt\n",
    "\n",
    "class Port:\n",
    "    def __init__(self, portId: str, name: str, portLocation: str, longitude: float, latitude: float, UN_LOCODE: str, countryName: str, ISO: str):\n",
    "        self.portId = portId\n",
    "        self.name = name\n",
    "        self.portLocation = portLocation\n",
    "        self.longitude = longitude\n",
    "        self.latitude = latitude\n",
    "        self.UN_LOCODE = UN_LOCODE\n",
    "        self.countryName = countryName\n",
    "        self.ISO = ISO\n",
    "\n",
    "class Schedule:\n",
    "    def __init__(self, vesselId: str, shippingLineId: str, shippingLineName: str, portId: str, portLatitude: float, portLongitude: float):\n",
    "        self.vesselId = vesselId\n",
    "        self.shippingLineId = shippingLineId\n",
    "        self.shippingLineName = shippingLineName\n",
    "        self.portId = portId\n",
    "        self.portLatitude = portLatitude\n",
    "        self.portLongitude = portLongitude\n",
    "\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    return geodesic((lat1, lon1), (lat2, lon2)).kilometers\n",
    "\n",
    "def main() -> None:\n",
    "    # Load AIS and optional datasets\n",
    "    ais_train = pd.read_csv('ais_train.csv', sep='|')\n",
    "    ais_test = pd.read_csv('ais_test.csv', sep='|')\n",
    "    vessels = pd.read_csv('vessels.csv', sep='|')\n",
    "    ports = pd.read_csv('ports.csv', sep='|')\n",
    "    schedules = pd.read_csv('schedules_to_may_2024.csv', sep='|')\n",
    "\n",
    "    # Merge AIS data with port data to get the port's latitude and longitude\n",
    "    merged_data = pd.merge(\n",
    "        ais_train, \n",
    "        ports[['portId', 'latitude', 'longitude']],  # Select relevant columns from ports\n",
    "        left_on='portId', right_on='portId', \n",
    "        suffixes=('', '_port')  # To differentiate vessel and port lat/lon\n",
    "    )\n",
    "\n",
    "    # Calculate distance to port\n",
    "    merged_data['distance_to_port'] = merged_data.apply(lambda row: calculate_distance(\n",
    "        row['latitude'], row['longitude'], row['latitude_port'], row['longitude_port']), axis=1)\n",
    "\n",
    "    # Extract time-related features\n",
    "    ais_train['timestamp'] = pd.to_datetime(ais_train['timestamp'])\n",
    "    ais_train['hour'] = ais_train['timestamp'].dt.hour\n",
    "    ais_train['day_of_week'] = ais_train['timestamp'].dt.dayofweek\n",
    "    # Create future latitude and longitude columns by shifting the original values\n",
    "    ais_train['future_latitude'] = ais_train['latitude'].shift(-1)\n",
    "    ais_train['future_longitude'] = ais_train['longitude'].shift(-1)\n",
    "\n",
    "    # Encode vessel type as numeric categories\n",
    "    ais_train['vessel_type_encoded'] = ais_train['vessel_type'].astype('category').cat.codes\n",
    "\n",
    "    # Use early data as training, later data as validation\n",
    "    train_data, val_data = train_test_split(ais_train, test_size=0.2, shuffle=False)\n",
    "    # Prepare the data for LSTM\n",
    "    def prepare_sequences(data, feature_cols, target_cols, sequence_length):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - sequence_length):\n",
    "            X.append(data[feature_cols].iloc[i:i+sequence_length].values)\n",
    "            y.append(data[target_cols].iloc[i+sequence_length].values)\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    # Define the feature columns\n",
    "    features = ['cog', 'sog', 'rot', 'heading', 'navstat', 'distance_to_port', 'hour', 'day_of_week', 'vessel_type_encoded']\n",
    "\n",
    "    # Define the target columns\n",
    "    target = ['future_latitude', 'future_longitude']  # Assuming you have future latitude and longitude columns\n",
    "\n",
    "    sequence_length = 5\n",
    "    X_train, y_train = prepare_sequences(train_data, features, target, sequence_length)\n",
    "    X_val, y_val = prepare_sequences(val_data, features, target, sequence_length)\n",
    "\n",
    "    # Build the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, return_sequences=False, input_shape=(sequence_length, len(features))))\n",
    "    model.add(Dense(2))  # Predict latitude and longitude\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "    model.summary()\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_val)\n",
    "\n",
    "    # Calculate geodetic distance between predictions and actual positions\n",
    "    val_data['pred_latitude'] = predictions[:, 0]\n",
    "    val_data['pred_longitude'] = predictions[:, 1]\n",
    "\n",
    "    val_data['error_distance'] = val_data.apply(lambda row: calculate_distance(\n",
    "        row['future_latitude'], row['future_longitude'], row['pred_latitude'], row['pred_longitude']), axis=1)\n",
    "\n",
    "    mean_error_distance = val_data['error_distance'].mean()\n",
    "    print(f'Mean Geodetic Error: {mean_error_distance} km')\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f4cc88-33a7-419c-9522-3b2642ed2623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
