{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc07cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c55a4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train = pd.read_csv('ais_train.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cc22e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test = pd.read_csv('ais_test.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e277710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'time' column to datetime\n",
    "train['time'] = pd.to_datetime(train['time'])\n",
    "test['time'] = pd.to_datetime(test['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d022f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map 'vesselId' to unique integers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train['vesselId'] = le.fit_transform(train['vesselId'])\n",
    "test['vesselId'] = le.transform(test['vesselId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb2d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort datasets by 'vesselId' and 'time'\n",
    "train = train.sort_values(by=['vesselId', 'time'])\n",
    "test = test.sort_values(by=['vesselId', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e48cb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'previous_lat', 'previous_lon', and 'delta_time' in the training set\n",
    "train['previous_lat'] = train.groupby('vesselId')['latitude'].shift(1)\n",
    "train['previous_lon'] = train.groupby('vesselId')['longitude'].shift(1)\n",
    "train['delta_time'] = train.groupby('vesselId')['time'].diff().dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6e4bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values resulting from the shift operation\n",
    "train = train.dropna(subset=['previous_lat', 'previous_lon', 'delta_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce249d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training features and targets\n",
    "X_train = train[['vesselId', 'previous_lat', 'previous_lon', 'delta_time']]\n",
    "y_train_lat = train['latitude']\n",
    "y_train_lon = train['longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c89851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize 'previous_lat', 'previous_lon', and 'delta_time' in the test set\n",
    "test['previous_lat'] = np.nan\n",
    "test['previous_lon'] = np.nan\n",
    "test['delta_time'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9b17aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve last known positions from the training set\n",
    "last_positions = train.groupby('vesselId').apply(lambda x: x.iloc[-1])[['vesselId', 'latitude', 'longitude', 'time']]\n",
    "last_positions = last_positions.set_index('vesselId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e4294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train separate Random Forest models for latitude and longitude\n",
    "model_lat = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "model_lat.fit(X_train, y_train_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a441bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lon = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "model_lon.fit(X_train, y_train_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2fdf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a list to collect the prediction results\n",
    "submission_rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1f8632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over each vessel in the test data\n",
    "for vessel_id in test['vesselId'].unique():\n",
    "    vessel_test_data = test[test['vesselId'] == vessel_id].copy()\n",
    "    vessel_test_data = vessel_test_data.sort_values(by='time')\n",
    "    \n",
    "    # Check if the vessel_id exists in the last_positions\n",
    "    if vessel_id in last_positions.index:\n",
    "        prev_lat = last_positions.loc[vessel_id, 'latitude']\n",
    "        prev_lon = last_positions.loc[vessel_id, 'longitude']\n",
    "        last_time = last_positions.loc[vessel_id, 'time']\n",
    "    else:\n",
    "        # If vessel_id is not in the training data, skip prediction\n",
    "        continue\n",
    "    \n",
    "    # Iterate over each record for the vessel\n",
    "    for idx, row in vessel_test_data.iterrows():\n",
    "        delta_time = (row['time'] - last_time).total_seconds()\n",
    "        \n",
    "        # Prepare the feature vector\n",
    "        X_test_row = pd.DataFrame({\n",
    "            'vesselId': [vessel_id],\n",
    "            'previous_lat': [prev_lat],\n",
    "            'previous_lon': [prev_lon],\n",
    "            'delta_time': [delta_time]\n",
    "        })\n",
    "        \n",
    "        # Predict latitude and longitude\n",
    "        predicted_lat = model_lat.predict(X_test_row)[0]\n",
    "        predicted_lon = model_lon.predict(X_test_row)[0]\n",
    "        \n",
    "        # Update previous values for the next iteration\n",
    "        prev_lat = predicted_lat\n",
    "        prev_lon = predicted_lon\n",
    "        last_time = row['time']\n",
    "        \n",
    "        # Append the prediction to the submission list\n",
    "        submission_rows.append({\n",
    "            'ID': row['ID'],\n",
    "            'longitude_predicted': predicted_lon,\n",
    "            'latitude_predicted': predicted_lat\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c46ae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a submission DataFrame from the list\n",
    "submission_df = pd.DataFrame(submission_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2d7690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the predictions with the test data based on 'ID'\n",
    "final_submission = test[['ID']].merge(submission_df, on='ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4533325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the submission file\n",
    "final_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
